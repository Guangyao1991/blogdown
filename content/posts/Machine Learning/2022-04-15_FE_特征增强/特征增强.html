---
title: "特征增强：数据清洗"
author: "Guangyao Zhao"
date: '2022-04-15T21:09:12-05:00'
image: FE.jpg
categories: machine learning
tags:
- machine learning
- feature engineering
---



<p>数据的清洗和增强指的是：</p>
<ul>
<li>清洗：调整已有的行和列。</li>
<li>增强：数据集中删除和添加新的列。</li>
</ul>
<div id="识别数据中的缺失值" class="section level2">
<h2>识别数据中的缺失值</h2>
<p>分析数据并了解缺失的数据是什么至关重要，这样才可以进一步处理缺失值。首先，先了解下本章使用的数据集：皮马印第安人糖尿病预测数据集。</p>
<div id="皮马印第安人糖尿病预测数据集" class="section level3">
<h3>皮马印第安人糖尿病预测数据集</h3>
<p>这个数据集和机器学习的二分类问题相对于。目标是判断判断<strong>此人五年内会不会得糖尿病？</strong>每列的含义如下：</p>
<ol style="list-style-type: decimal">
<li>怀孕次数</li>
<li>口服葡萄糖耐量实验中的两小时血浆葡萄糖浓度</li>
<li>舒张压</li>
<li>两小时血清胰岛素浓度</li>
<li>体重指数</li>
<li>糖尿病家族函数</li>
<li>年龄</li>
<li>类变量（0或1，代表无或有糖尿病）</li>
</ol>
</div>
<div id="探索性数据分析exploratory-data-analysis-eda" class="section level3">
<h3>探索性数据分析（exploratory data analysis, EDA）</h3>
<pre class="python"><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use(&#39;fivethirtyeight&#39;)  # 可视化主题

pima = pd.read_csv(&#39;data/pima.data&#39;)  # 导入数据
pima.head()</code></pre>
<pre><code>##    6  148  72  35    0  33.6  0.627  50  1
## 0  1   85  66  29    0  26.6  0.351  31  0
## 1  8  183  64   0    0  23.3  0.672  32  1
## 2  1   89  66  23   94  28.1  0.167  21  0
## 3  0  137  40  35  168  43.1  2.288  33  1
## 4  5  116  74   0    0  25.6  0.201  30  0</code></pre>
<p>观察前几行数据，但是表格没有列名。下面手动添加：</p>
<pre class="python"><code>pima_column_names = [
    &#39;times_pregnant&#39;, &#39;plasma_glucose_concentration&#39;,
    &#39;diastolic_blood_pressure&#39;, &#39;triceps_thickness&#39;, &#39;serum_insulin&#39;, &#39;bmi&#39;,
    &#39;pedigree_function&#39;, &#39;age&#39;, &#39;onset_diabetes&#39;
] # 列名称

pima = pd.read_csv(&#39;data/pima.data&#39;, names=pima_column_names) # 读取数据
pima.head()</code></pre>
<pre><code>##    times_pregnant  plasma_glucose_concentration  ...  age  onset_diabetes
## 0               6                           148  ...   50               1
## 1               1                            85  ...   31               0
## 2               8                           183  ...   32               1
## 3               1                            89  ...   21               0
## 4               0                           137  ...   33               1
## 
## [5 rows x 9 columns]</code></pre>
<p>这样看起来好多了。先算一下空准确率：</p>
<pre class="python"><code>pima[&#39;onset_diabetes&#39;].value_counts(normalize=True)</code></pre>
<pre><code>## 0    0.651042
## 1    0.348958
## Name: onset_diabetes, dtype: float64</code></pre>
<p>由此可看出，空准确率为<span class="math inline">\(65\%\)</span>，所以模型的目标必须超过此值。下面做一些可视化操作，来了解下此数据集：</p>
<pre class="python"><code>col = &#39;plasma_glucose_concentration&#39;

plt.hist(pima[pima[&#39;onset_diabetes&#39;] == 0][col],
         10,
         alpha=0.5,
         label=&#39;non-diabetes&#39;)</code></pre>
<pre><code>## (array([  3.,   0.,   4.,  28., 129., 167.,  99.,  49.,  12.,   9.]), array([  0. ,  19.7,  39.4,  59.1,  78.8,  98.5, 118.2, 137.9, 157.6,
##        177.3, 197. ]), &lt;BarContainer object of 10 artists&gt;)</code></pre>
<pre class="python"><code>plt.hist(pima[pima[&#39;onset_diabetes&#39;] == 1][col],
         10,
         alpha=0.5,
         label=&#39;diabetes&#39;)</code></pre>
<pre><code>## (array([ 2.,  0.,  0.,  1., 13., 54., 63., 51., 45., 39.]), array([  0. ,  19.9,  39.8,  59.7,  79.6,  99.5, 119.4, 139.3, 159.2,
##        179.1, 199. ]), &lt;BarContainer object of 10 artists&gt;)</code></pre>
<pre class="python"><code>plt.legend(loc=&#39;upper right&#39;)
plt.xlabel(&#39;col&#39;)
plt.ylabel(&#39;Frequency&#39;)
plt.title(&#39;Histogram of {x}&#39;.format(x=col))
plt.show()</code></pre>
<p><img src="/posts/Machine Learning/2022-04-15_FE_特征增强/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>看起来是否患有糖尿病和血浆葡萄糖浓度有很大关系。继续绘制其它列的直方图：</p>
<pre class="python"><code>for col in [&#39;bmi&#39;, &#39;diastolic_blood_pressure&#39;, &#39;plasma_glucose_concentration&#39;]:
    plt.hist(pima[pima[&#39;onset_diabetes&#39;] == 0][col],
             10,
             alpha=0.5,
             label=&#39;non-diabetes&#39;)
    plt.hist(pima[pima[&#39;onset_diabetes&#39;] == 1][col],
             10,
             alpha=0.5,
             label=&#39;diabetes&#39;)
    plt.legend(loc=&#39;upper right&#39;)
    plt.xlabel(&#39;col&#39;)
    plt.ylabel(&#39;Frequency&#39;)
    plt.title(&#39;Histogram of {x}&#39;.format(x=col))
    plt.show()</code></pre>
<p><img src="/posts/Machine Learning/2022-04-15_FE_特征增强/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA_files/figure-html/unnamed-chunk-5-3.png" width="672" /><img src="/posts/Machine Learning/2022-04-15_FE_特征增强/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA_files/figure-html/unnamed-chunk-5-4.png" width="672" /><img src="/posts/Machine Learning/2022-04-15_FE_特征增强/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA_files/figure-html/unnamed-chunk-5-5.png" width="672" /><img src="/posts/Machine Learning/2022-04-15_FE_特征增强/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA_files/figure-html/unnamed-chunk-5-6.png" width="672" /></p>
<p>从以上结果可看出，两类人在不同的特征下有很大的差别。为了量化这些特征和观察值之间的关系，引入相关矩阵：</p>
<pre class="python"><code>sns.heatmap(pima.corr())  #! Tip：在 plt 中无 heatmap</code></pre>
<p><img src="/posts/Machine Learning/2022-04-15_FE_特征增强/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA_files/figure-html/unnamed-chunk-6-11.png" width="672" /></p>
<p>相关矩阵显示，血浆葡萄糖浓度和糖尿病有很强的相关性，下面显示出具体数值：</p>
<pre class="python"><code>pima.corr()</code></pre>
<pre><code>##                               times_pregnant  ...  onset_diabetes
## times_pregnant                      1.000000  ...        0.221898
## plasma_glucose_concentration        0.129459  ...        0.466581
## diastolic_blood_pressure            0.141282  ...        0.065068
## triceps_thickness                  -0.081672  ...        0.074752
## serum_insulin                      -0.073535  ...        0.130548
## bmi                                 0.017683  ...        0.292695
## pedigree_function                  -0.033523  ...        0.173844
## age                                 0.544341  ...        0.238356
## onset_diabetes                      0.221898  ...        1.000000
## 
## [9 rows x 9 columns]</code></pre>
<p>查看下数据集中有没有缺失值：</p>
<pre class="python"><code>pima.isnull().sum()  #! Tip:自动按列计算</code></pre>
<pre><code>## times_pregnant                  0
## plasma_glucose_concentration    0
## diastolic_blood_pressure        0
## triceps_thickness               0
## serum_insulin                   0
## bmi                             0
## pedigree_function               0
## age                             0
## onset_diabetes                  0
## dtype: int64</code></pre>
<pre class="python"><code>pima.describe()</code></pre>
<pre><code>##        times_pregnant  plasma_glucose_concentration  ...         age  onset_diabetes
## count      768.000000                    768.000000  ...  768.000000      768.000000
## mean         3.845052                    120.894531  ...   33.240885        0.348958
## std          3.369578                     31.972618  ...   11.760232        0.476951
## min          0.000000                      0.000000  ...   21.000000        0.000000
## 25%          1.000000                     99.000000  ...   24.000000        0.000000
## 50%          3.000000                    117.000000  ...   29.000000        0.000000
## 75%          6.000000                    140.250000  ...   41.000000        1.000000
## max         17.000000                    199.000000  ...   81.000000        1.000000
## 
## [8 rows x 9 columns]</code></pre>
<p>仔细查看下统计量，能发现其实有异常。比如 BMI 的最小值为<span class="math inline">\(0\)</span>这是违反常识的。原因可能为在数据集中的缺失值或者异常值都用了<span class="math inline">\(0\)</span>填充。继续观察，以下特征最小值为<span class="math inline">\(0\)</span>：</p>
<ul>
<li>times_pregnant</li>
<li>plasma_glucose_concentration</li>
<li>diastolic_blood_pressure</li>
<li>triceps_thickness</li>
<li>serum_insulin</li>
<li>bmi</li>
<li>onset_diabetes</li>
</ul>
<p>其中，onset_diabetes的<span class="math inline">\(0\)</span>代表没有糖尿病，人也可以怀孕<span class="math inline">\(0\)</span>次，所以可知以下缺失值用<span class="math inline">\(0\)</span>填充：</p>
<ul>
<li>plasma_glucose_concentration</li>
<li>diastolic_blood_pressure</li>
<li>triceps_thickness</li>
<li>serum_insulin</li>
<li>bmi</li>
</ul>
<p>至此可知，数据集中还是存在缺失值，只不过用<span class="math inline">\(0\)</span>填充过了。数据集一般会用以下方式填充：</p>
<ul>
<li><span class="math inline">\(0\)</span></li>
<li><code>unknown</code></li>
<li><code>?</code></li>
</ul>
</div>
</div>
<div id="处理数据集中的缺失值" class="section level2">
<h2>处理数据集中的缺失值</h2>
<p>大部分的算法不能处理缺失值，所以需要提前对其进行特殊处理：</p>
<ul>
<li>删除含有缺失值的行</li>
<li>填充缺失值</li>
</ul>
<p>在进一步处理之前，先用 Python 中的<code>None</code>填充所有的数字<span class="math inline">\(0\)</span>。这样 Pandas 中的<code>fillna</code>和<code>dropna</code>方法就可以正常工作了：</p>
<pre class="python"><code>columns = [
    &#39;plasma_glucose_concentration&#39;, &#39;diastolic_blood_pressure&#39;,
    &#39;triceps_thickness&#39;, &#39;serum_insulin&#39;, &#39;bmi&#39;
]

for col in columns:
    pima[col].replace([0], [None], inplace=True)

pima.isnull().sum()</code></pre>
<pre><code>## times_pregnant                    0
## plasma_glucose_concentration      5
## diastolic_blood_pressure         35
## triceps_thickness               227
## serum_insulin                   374
## bmi                              11
## pedigree_function                 0
## age                               0
## onset_diabetes                    0
## dtype: int64</code></pre>
<p>可以看出triceps_thickness和serum_insulin中的缺失值还是很多的。查看下前几行数据：</p>
<pre class="python"><code>pima.head()</code></pre>
<pre><code>##    times_pregnant plasma_glucose_concentration  ... age onset_diabetes
## 0               6                          148  ...  50              1
## 1               1                           85  ...  31              0
## 2               8                          183  ...  32              1
## 3               1                           89  ...  21              0
## 4               0                          137  ...  33              1
## 
## [5 rows x 9 columns]</code></pre>
<p>做一些描述统计：</p>
<pre class="python"><code>pima.describe()</code></pre>
<pre><code>##        times_pregnant  pedigree_function         age  onset_diabetes
## count      768.000000         768.000000  768.000000      768.000000
## mean         3.845052           0.471876   33.240885        0.348958
## std          3.369578           0.331329   11.760232        0.476951
## min          0.000000           0.078000   21.000000        0.000000
## 25%          1.000000           0.243750   24.000000        0.000000
## 50%          3.000000           0.372500   29.000000        0.000000
## 75%          6.000000           0.626250   41.000000        1.000000
## max         17.000000           2.420000   81.000000        1.000000</code></pre>
<p>注意<code>describe</code>方法不包括缺失值的列。</p>
<div id="删除有害行" class="section level3">
<h3>删除有害行</h3>
<p>在处理缺失值中，最常见的办法就是无脑式删除存在缺失值的行：</p>
<pre class="python"><code>pima_dropped = pima.dropna()  # 删除缺失值的行
num_rows_lost = round(100 * (pima.shape[0] - pima_dropped.shape[0]) /
                      pima.shape[0]) # 查看下删除的比例

print(&#39;retained {x}% of rows.&#39;.format(x=num_rows_lost))</code></pre>
<pre><code>## retained 49% of rows.</code></pre>
<p>竟然损失了元数据集中<span class="math inline">\(51\%\)</span>的行。这真的是代价太大了。比较下转换前后的统计数据：</p>
<pre class="python"><code>pima.mean()</code></pre>
<pre><code>## times_pregnant                    3.845052
## plasma_glucose_concentration    121.686763
## diastolic_blood_pressure         72.405184
## triceps_thickness                29.153420
## serum_insulin                   155.548223
## bmi                              32.457464
## pedigree_function                 0.471876
## age                              33.240885
## onset_diabetes                    0.348958
## dtype: float64</code></pre>
<pre class="python"><code>pima_dropped.mean()</code></pre>
<pre><code>## times_pregnant                    3.301020
## plasma_glucose_concentration    122.627551
## diastolic_blood_pressure         70.663265
## triceps_thickness                29.145408
## serum_insulin                   156.056122
## bmi                              33.086224
## pedigree_function                 0.523046
## age                              30.864796
## onset_diabetes                    0.331633
## dtype: float64</code></pre>
<p>为了更好的了解其变化，创建一个新图表，将每列均值变化百分比可视化。</p>
<pre class="python"><code>(pima_dropped.mean() - pima.mean()) / pima.mean()</code></pre>
<pre><code>## times_pregnant                 -0.141489
## plasma_glucose_concentration    0.007731
## diastolic_blood_pressure       -0.024058
## triceps_thickness              -0.000275
## serum_insulin                   0.003265
## bmi                             0.019372
## pedigree_function               0.108439
## age                            -0.071481
## onset_diabetes                 -0.049650
## dtype: float64</code></pre>
<pre class="python"><code>ax = ((pima_dropped.mean() - pima.mean()) / pima.mean()).plot(
    kind=&#39;bar&#39;, title=&#39;change in average column values&#39;)

ax.set_ylabel(&#39;% change&#39;)</code></pre>
<p><img src="/posts/Machine Learning/2022-04-15_FE_特征增强/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA_files/figure-html/unnamed-chunk-14-13.png" width="672" /></p>
<p>可以看到均值在删除缺失值后的改变很大，即删除行会严重影响数据分布。下面进行一些简单的机器学习。</p>
<pre class="python"><code>from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# 准备数据集
X_dropped = pima_dropped.drop(&#39;onset_diabetes&#39;, axis=1)
print(&quot;learning from {} rows&quot;.format(X_dropped.shape[0]))</code></pre>
<pre><code>## learning from 392 rows</code></pre>
<pre class="python"><code>y_dropped = pima_dropped[&#39;onset_diabetes&#39;]

# 需要试验的 KNN 模型参数
knn_params = {&#39;n_neighbors&#39;: [1, 2, 3, 4, 5, 6, 7]}
knn = KNeighborsClassifier()

# 网格搜索
grid = GridSearchCV(knn, knn_params)
grid.fit(X_dropped, y_dropped)

# 输出最佳参数</code></pre>
<pre><code>## GridSearchCV(estimator=KNeighborsClassifier(),
##              param_grid={&#39;n_neighbors&#39;: [1, 2, 3, 4, 5, 6, 7]})</code></pre>
<pre class="python"><code>print(grid.best_score_, grid.best_params_)</code></pre>
<pre><code>## 0.7348263550795197 {&#39;n_neighbors&#39;: 7}</code></pre>
<p>从以上可看出最佳正确率为<span class="math inline">\(73\%\)</span>，最佳邻居数为<span class="math inline">\(7\)</span>。但是这种直接删除缺失值的方法不太妥当。</p>
</div>
<div id="填充缺失值" class="section level3">
<h3>填充缺失值</h3>
<p>填充数据是处理缺失值的一种更复杂的方法。<strong>填充</strong>指的是利用现有知识和数据来确定缺失的数值，并填充的行为。常用的方法是用此列非空值部分的均值填充：</p>
<pre class="python"><code>pima.isnull().sum()</code></pre>
<pre><code>## times_pregnant                    0
## plasma_glucose_concentration      5
## diastolic_blood_pressure         35
## triceps_thickness               227
## serum_insulin                   374
## bmi                              11
## pedigree_function                 0
## age                               0
## onset_diabetes                    0
## dtype: int64</code></pre>
<p>接下来看一下<code>plasma_glucose_concentration</code>的缺失值：</p>
<pre class="python"><code>empty_plasma_index = pima[
    pima[&#39;plasma_glucose_concentration&#39;].isnull()].index  # 空值的 index

pima.loc[empty_plasma_index][&#39;plasma_glucose_concentration&#39;]</code></pre>
<pre><code>## 75     None
## 182    None
## 342    None
## 349    None
## 502    None
## Name: plasma_glucose_concentration, dtype: object</code></pre>
<p>现在可以用<code>fillna</code>方法，将其填充为均值：</p>
<pre class="python"><code>pima[&#39;plasma_glucose_concentration&#39;].fillna(
    pima[&#39;plasma_glucose_concentration&#39;].mean(), inplace=True)

pima.isnull().sum()</code></pre>
<pre><code>## times_pregnant                    0
## plasma_glucose_concentration      0
## diastolic_blood_pressure         35
## triceps_thickness               227
## serum_insulin                   374
## bmi                              11
## pedigree_function                 0
## age                               0
## onset_diabetes                    0
## dtype: int64</code></pre>
<p>可以看到<code>plasma_glucose_concentration</code>无缺失值，查看下填充后的值是什么：</p>
<pre class="python"><code>pima.loc[empty_plasma_index][&#39;plasma_glucose_concentration&#39;]</code></pre>
<pre><code>## 75     121.686763
## 182    121.686763
## 342    121.686763
## 349    121.686763
## 502    121.686763
## Name: plasma_glucose_concentration, dtype: float64</code></pre>
<p>在 sklearn 中有专门填补缺失值的方法：</p>
<pre class="python"><code>from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy=&#39;mean&#39;)
pima_imputed = imputer.fit_transform(pima)</code></pre>
<p>此处有一个小问题要处理，sklearn 输出的不是 DataFrame，而是 Numpy 数组，此处将其转化为 DataFrame：</p>
<pre class="python"><code>pima_imputed = pd.DataFrame(pima_imputed, columns=pima_column_names)
pima_imputed.head()</code></pre>
<pre><code>##    times_pregnant  plasma_glucose_concentration  ...   age  onset_diabetes
## 0             6.0                         148.0  ...  50.0             1.0
## 1             1.0                          85.0  ...  31.0             0.0
## 2             8.0                         183.0  ...  32.0             1.0
## 3             1.0                          89.0  ...  21.0             0.0
## 4             0.0                         137.0  ...  33.0             1.0
## 
## [5 rows x 9 columns]</code></pre>
<p>检查一下<code>plasma_glucose_concentration</code>列的填充值是否和我们手动计算的一样：</p>
<pre class="python"><code>pima_imputed.loc[empty_plasma_index][&#39;plasma_glucose_concentration&#39;]</code></pre>
<pre><code>## 75     121.686763
## 182    121.686763
## 342    121.686763
## 349    121.686763
## 502    121.686763
## Name: plasma_glucose_concentration, dtype: float64</code></pre>
<p>最后检查一下是否含有缺失值：</p>
<pre class="python"><code>pima_imputed.isnull().sum()</code></pre>
<pre><code>## times_pregnant                  0
## plasma_glucose_concentration    0
## diastolic_blood_pressure        0
## triceps_thickness               0
## serum_insulin                   0
## bmi                             0
## pedigree_function               0
## age                             0
## onset_diabetes                  0
## dtype: int64</code></pre>
<p>接下来尝试填充一下其他值，看看对 KNN 的影响。首先采用<span class="math inline">\(0\)</span>填充：</p>
<pre class="python"><code>pima_zero = pima.fillna(0)

X_zero = pima_zero.drop(&#39;onset_diabetes&#39;, axis=1)
y_zero = pima_zero[&#39;onset_diabetes&#39;]

knn_params = {&#39;n_neighbors&#39;: range(1, 8)}
grid = GridSearchCV(knn, knn_params)
grid.fit(X_zero, y_zero)</code></pre>
<pre><code>## GridSearchCV(estimator=KNeighborsClassifier(),
##              param_grid={&#39;n_neighbors&#39;: range(1, 8)})</code></pre>
<pre class="python"><code>print(grid.best_score_, grid.best_params_)</code></pre>
<pre><code>## 0.7409387997623291 {&#39;n_neighbors&#39;: 7}</code></pre>
</div>
<div id="在机器学习流水线中填充值" class="section level3">
<h3>在机器学习流水线中填充值</h3>
<p>首先谈论下什么是机器学习流水线，在机器学习中谈论<strong>流水线</strong>的时候，一般指的是在被解读为最终输出之前，原始数据不仅仅进入一种学习算法，而是经过各种预处理步骤，乃至多种学习算法。</p>
<p><code>Impute</code>类就是为了流水线而存在的，<strong>这是因为学习算法的目标是泛化训练集的模式并将其应用于测试集。</strong> 如果在划分数据集和应用算法之前直接对整个数据集填充值，那就是在作弊。</p>
<pre class="python"><code>from sklearn.model_selection import train_test_split

X = pima.iloc[:, :-1]
y = pima.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    random_state=1,
                                                    test_size=0.3)

# 注意此处的填充方式
X_train = X_train.fillna(X_train.mean())
X_test = X_test.fillna(X_test.mean())</code></pre>
<p>为了分别保持训练集和测试集的纯净性，应该分别进行数值填充，而不应该一起。下面进行模型训练：</p>
<pre class="python"><code>knn = KNeighborsClassifier()

knn.fit(X_train, y_train)</code></pre>
<pre><code>## KNeighborsClassifier()</code></pre>
<pre class="python"><code>print(knn.score(X_test, y_test))</code></pre>
<pre><code>## 0.7705627705627706</code></pre>
<p>以下介绍利用流水线的整个机器学习的流程：</p>
<pre class="python"><code>from sklearn.pipeline import Pipeline

knn_params = {
    &#39;classify__n_neighbors&#39;: range(1, 8)
}  # 注意，classify 和 n 的中间为两条下划线
knn = KNeighborsClassifier()

X = pima.iloc[:,:-1]
y = pima.iloc[:,-1]

mean_impute = Pipeline([(&#39;imputer&#39;, SimpleImputer(strategy=&#39;mean&#39;)),
                        (&#39;classify&#39;, knn)])

grid = GridSearchCV(mean_impute, knn_params)
grid.fit(X_train, y_train)</code></pre>
<pre><code>## GridSearchCV(estimator=Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer()),
##                                        (&#39;classify&#39;, KNeighborsClassifier())]),
##              param_grid={&#39;classify__n_neighbors&#39;: range(1, 8)})</code></pre>
<pre class="python"><code>print(grid.best_score_, grid.best_params_)</code></pre>
<pre><code>## 0.7225856697819315 {&#39;classify__n_neighbors&#39;: 7}</code></pre>
</div>
</div>
<div id="标准化和归一化" class="section level2">
<h2>标准化和归一化</h2>
<p>到目前为止，已经知道了如何识别数据类型和缺失值，以及怎么处理缺失值。下面学习下怎么处理数据（特征），以进一步增强机器学习流水线。下面查看下数据分布：</p>
<pre class="python"><code>impute = SimpleImputer(strategy=&#39;mean&#39;)

pima_imputed_mean = pd.DataFrame(impute.fit_transform(pima),
                                 columns=pima_column_names)

pima_imputed_mean.hist(figsize=(15, 15))</code></pre>
<pre><code>## array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;times_pregnant&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;plasma_glucose_concentration&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;diastolic_blood_pressure&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;triceps_thickness&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;serum_insulin&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;bmi&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;pedigree_function&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;age&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;onset_diabetes&#39;}&gt;]], dtype=object)</code></pre>
<p>从上图可看出，每列的均值、最小值、最大值和标准差的差别都很大。这有什么影响呢？机器学习模型受尺度的影响很大，尤其是训练速度。</p>
<p>在统一尺度下观察下数据分布：</p>
<pre class="python"><code>pima_imputed_mean.hist(figsize=(15, 15), sharex=True)</code></pre>
<pre><code>## array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;times_pregnant&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;plasma_glucose_concentration&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;diastolic_blood_pressure&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;triceps_thickness&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;serum_insulin&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;bmi&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;pedigree_function&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;age&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;onset_diabetes&#39;}&gt;]], dtype=object)</code></pre>
<p>很明显所有的数据尺度都不相同，所以需要归一化操作。<strong>归一化的操作的目的在于行和列对其并转化为一致的规则。</strong> 例如归一化常常将所有定量列转化为同一个静态范围中的值，常用的归一化操作有以下三种：</p>
<ul>
<li><span class="math inline">\(z\)</span>分数标准化</li>
<li>min-max 标准化</li>
<li>行归一化。</li>
</ul>
<div id="z分数标准化" class="section level3">
<h3><span class="math inline">\(z\)</span>分数标准化</h3>
<p><span class="math inline">\(z\)</span>分数标准化的公式如下：</p>
<p><span class="math display">\[
z = \frac{(x-\mu)}{\sigma}
\]</span></p>
<p>代码如下：</p>
<pre class="python"><code>from sklearn.preprocessing import StandardScaler

scale = StandardScaler()

pima_imputed_mean_scaled = pd.DataFrame(scale.fit_transform(pima_imputed_mean),
                                        columns=pima_column_names)

pima_imputed_mean_scaled.hist(figsize=(15, 15), sharex=True)</code></pre>
<pre><code>## array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;times_pregnant&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;plasma_glucose_concentration&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;diastolic_blood_pressure&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;triceps_thickness&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;serum_insulin&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;bmi&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;pedigree_function&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;age&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;onset_diabetes&#39;}&gt;]], dtype=object)</code></pre>
<p>从上图可看出，整个数据集都更加紧密了，现在将<code>StandarScaler</code>方法插入之前的机器学习流水线中：</p>
<pre class="python"><code>knn_params = {
    &#39;imputer__strategy&#39;: [&#39;mean&#39;, &#39;median&#39;],
    &#39;classify__n_neighbors&#39;: range(1, 7)
}

mean_imputed_standardize = Pipeline([(&#39;imputer&#39;, SimpleImputer()),
                                     (&#39;stadardize&#39;, StandardScaler()),
                                     (&#39;classify&#39;, knn)])

X = pima.drop(&#39;onset_diabetes&#39;, axis=1)
y = pima[&#39;onset_diabetes&#39;]

grid = GridSearchCV(mean_imputed_standardize, knn_params)
grid.fit(X, y)</code></pre>
<pre><code>## GridSearchCV(estimator=Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer()),
##                                        (&#39;stadardize&#39;, StandardScaler()),
##                                        (&#39;classify&#39;, KNeighborsClassifier())]),
##              param_grid={&#39;classify__n_neighbors&#39;: range(1, 7),
##                          &#39;imputer__strategy&#39;: [&#39;mean&#39;, &#39;median&#39;]})</code></pre>
<pre class="python"><code>print(grid.best_score_, grid.best_params_)</code></pre>
<pre><code>## 0.7473983532807063 {&#39;classify__n_neighbors&#39;: 6, &#39;imputer__strategy&#39;: &#39;mean&#39;}</code></pre>
</div>
<div id="min-max-标准化" class="section level3">
<h3>min-max 标准化</h3>
<p>min-max 标准化的公式如下：</p>
<p><span class="math display">\[
m = \frac{x-x_{min}}{x_{max}-x_{min}}
\]</span></p>
<pre class="python"><code>from sklearn.preprocessing import MinMaxScaler

min_max = MinMaxScaler()
pima_min_maxed = pd.DataFrame(min_max.fit_transform(pima_imputed),
                              columns=pima_column_names)

pima_min_maxed.hist(figsize=(15, 15), sharex=True)</code></pre>
<pre><code>## array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;times_pregnant&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;plasma_glucose_concentration&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;diastolic_blood_pressure&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;triceps_thickness&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;serum_insulin&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;bmi&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;pedigree_function&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;age&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;onset_diabetes&#39;}&gt;]], dtype=object)</code></pre>
</div>
<div id="行归一化" class="section level3">
<h3>行归一化</h3>
<p>行归一化不是计算每列的统计值，而是保证每行有<strong>单位范数</strong>，即每行的向量长度相同，即每行的：</p>
<p><span class="math display">\[
\Vert x\Vert=\sqrt[]{x_1^2+x_2^2+...,x_n^2}
\]</span></p>
<p>在此处我们使用 <strong>L2 范数</strong>。</p>
<pre class="python"><code>from sklearn.preprocessing import Normalizer

normalize = Normalizer()
pima_normalized = pd.DataFrame(normalize.fit_transform(pima_imputed),
                               columns=pima_column_names)

pima_normalized.hist(figsize=(15, 15), sharey=True)</code></pre>
<pre><code>## array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;times_pregnant&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;plasma_glucose_concentration&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;diastolic_blood_pressure&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;triceps_thickness&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;serum_insulin&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;bmi&#39;}&gt;],
##        [&lt;AxesSubplot:title={&#39;center&#39;:&#39;pedigree_function&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;age&#39;}&gt;,
##         &lt;AxesSubplot:title={&#39;center&#39;:&#39;onset_diabetes&#39;}&gt;]], dtype=object)</code></pre>
</div>
</div>
